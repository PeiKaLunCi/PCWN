# -*- coding: utf-8 -*-
"""admm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C2b19vC_XCzuayO1ncrNXeWx9rcYxGZI

Setup environment
"""

# Commented out IPython magic to ensure Python compatibility.
#try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
#except Exception:
#  pass
import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  print('GPU device not found')#raise SystemError('GPU device not found')
else:
  print('Found GPU at: {}'.format(device_name))

"""Solver for L1-norm"""
import sys
sys.path.append('')
import numpy as np
import scipy as sp
from scipy.sparse.linalg import LinearOperator
import matplotlib
import matplotlib.pyplot as plt
#from vec import vec
import timeit
import pywt
import os

#def vec(x): #version from vec, don't these two clash
#    return np.reshape(x, (-1), order='F')

def vec(x):
    return x.ravel(order='F')


def sigmoid(x):
    return 1/(1+np.exp(-x))


def wavelet_transform(x):
    w_coeffs_rgb = [] # np.zeros(x.shape[3], np.prod(x.shape))
    for i in range(x.shape[2]):
        w_coeffs_list = pywt.wavedec2(x[:,:,i], 'db4', level=None, mode='periodization')
        w_coeffs, coeff_slices = pywt.coeffs_to_array(w_coeffs_list)
        w_coeffs_rgb.append(w_coeffs)

    w_coeffs_rgb = np.array(w_coeffs_rgb)
    return w_coeffs_rgb, coeff_slices


def inverse_wavelet_transform(w_coeffs_rgb, coeff_slices, x_shape):
    x_hat = np.zeros(x_shape)
    for i in range(w_coeffs_rgb.shape[0]):
        w_coeffs_list = pywt.array_to_coeffs(w_coeffs_rgb[i,:,:], coeff_slices)
        x_hat[:,:,i] = pywt.waverecn(w_coeffs_list, wavelet='db4', mode='periodization')
    return x_hat


def soft_threshold(x, beta):
    y = np.maximum(0, x-beta) - np.maximum(0, -x-beta)
    return y



# A_fun, AT_fun takes a vector (d,1) or (d,) as input
def solve_l1(y, A_fun, AT_fun, lambda_l1, reshape_img_fun, show_img_progress=False, alpha=0.2, max_iter=100, solver_tol=1e-6):
    """ See Wang, Yu, Wotao Yin, and Jinshan Zeng. "Global convergence of ADMM in nonconvex nonsmooth optimization."
    arXiv preprint arXiv:1511.06324 (2015).
    It provides convergence condition: basically with large enough alpha, the program will converge. """

    #result_folder = '%s/iter-imgs' % base_folder
    #if not os.path.exists(result_folder):
        #os.makedirs(result_folder)

    obj_lss = np.zeros(max_iter)
    x_zs = np.zeros(max_iter)
    u_norms = np.zeros(max_iter)
    times = np.zeros(max_iter)

    ATy = AT_fun(y)
    x_shape = ATy.shape
    d = np.prod(x_shape)

    def A_cgs_fun(x):
        x = np.reshape(x, x_shape, order='F')
        y = AT_fun(A_fun(x)) + alpha * x
        return vec(y)
    A_cgs = LinearOperator((d,d), matvec=A_cgs_fun, dtype='float')

    def compute_p_inv_A(b, z0):
        (z,info) = sp.sparse.linalg.cgs(A_cgs, vec(b), x0=vec(z0), tol=1e-3, maxiter=100)
        if info > 0:
            print('cgs convergence to tolerance not achieved')
        elif info <0:
            print('cgs gets illegal input or breakdown')
        z = np.reshape(z, x_shape, order='F')
        return z


    def A_cgs_fun_init(x):
        x = np.reshape(x, x_shape, order='F')
        y = AT_fun(A_fun(x))
        return vec(y)
    A_cgs_init = LinearOperator((d,d), matvec=A_cgs_fun_init, dtype='float')

    def compute_init(b, z0):
        (z,info) = sp.sparse.linalg.cgs(A_cgs_init, vec(b), x0=vec(z0), tol=1e-2)
        if info > 0:
            print('cgs convergence to tolerance not achieved')
        elif info <0:
            print('cgs gets illegal input or breakdown')
        z = np.reshape(z, x_shape, order='F')
        return z

    # initialize z and u
    z = compute_init(ATy, ATy)
    u = np.zeros(x_shape)


    plot_normalozer = matplotlib.colors.Normalize(vmin=0.0, vmax=1.0, clip=True)


    start_time = timeit.default_timer()

    for iter in range(max_iter):

        # x-update
        net_input = z+u
        Wzu, wbook = wavelet_transform(net_input)
        q = soft_threshold(Wzu, lambda_l1/alpha)
        x = inverse_wavelet_transform(q, wbook, x_shape)
        x = np.reshape(x, x_shape)

        # z-update
        b = ATy + alpha * (x - u)
        z = compute_p_inv_A(b, z)

        # u-update
        u += z - x;

        if show_img_progress == True:

            fig = plt.figure('current_sol')
            plt.gcf().clear()
            fig.canvas.set_window_title('iter %d' % iter)
            plt.subplot(1,3,1)
            plt.imshow(reshape_img_fun(np.clip(x, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            #plt.imshow(np.clip(x, 0.0, 1.0), interpolation='nearest', norm=plot_normalozer)
            plt.title('x')
            plt.subplot(1,3,2)
            plt.imshow(reshape_img_fun(np.clip(z, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            #plt.imshow(np.clip(z, 0.0, 1.0), interpolation='nearest', norm=plot_normalozer)
            plt.title('z')
            plt.subplot(1,3,3)
            plt.imshow(reshape_img_fun(np.clip(net_input, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            plt.title('netin')
            plt.pause(0.00001)


        obj_ls = 0.5 * np.sum(np.square(y - A_fun(x)))
        x_z = np.sqrt(np.mean(np.square(x-z)))
        u_norm = np.sqrt(np.mean(np.square(u)))

        print('iter = %d: obj_ls = %.3e  |x-z| = %.3e  u_norm = %.3e' % (iter, obj_ls, x_z, u_norm))


        obj_lss[iter] = obj_ls
        x_zs[iter] = x_z
        u_norms[iter] = u_norm
        times[iter] = timeit.default_timer() - start_time


        ## save images
        #filename = '%s/%d-x.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(x, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))
        #filename = '%s/%d-z.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(z, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))
        #filename = '%s/%d-u.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(u, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))

        #_ = raw_input('')

        if x_z < solver_tol:
            break

    infos = {'obj_lss': obj_lss, 'x_zs': x_zs, 'u_norms': u_norms,
             'times': times, 'alpha':alpha, 'lambda_l1':lambda_l1,
             'max_iter':max_iter, 'solver_tol':solver_tol}


    return (x, z, u, infos)


# Alternative solver based on Bernie's ADMM derivation
# A_fun, AT_fun takes a vector (d,1) or (d,) as input
def solve_l1_alt(y, A_fun, AT_fun, lambda_l1, reshape_img_fun, show_img_progress=False, alpha=0.2, max_iter=100, solver_tol=1e-6):
    """ See Wang, Yu, Wotao Yin, and Jinshan Zeng. "Global convergence of ADMM in nonconvex nonsmooth optimization."
    arXiv preprint arXiv:1511.06324 (2015).
    It provides convergence condition: basically with large enough alpha, the program will converge. """

    #result_folder = '%s/iter-imgs' % base_folder
    #if not os.path.exists(result_folder):
        #os.makedirs(result_folder)
    print("solve_l1_alt, alpha = ",alpha, "lambda_l1 = ", lambda_l1)
    obj_lss = np.zeros(max_iter)
    x_zs = np.zeros(max_iter)
    u_norms = np.zeros(max_iter)
    times = np.zeros(max_iter)

    ATy = AT_fun(y)
    x_shape = ATy.shape
    d = np.prod(x_shape)

    def A_cgs_fun(x):
        x = np.reshape(x, x_shape, order='F')
        y = AT_fun(A_fun(x)) + x #alpha * x
        return vec(y)
    A_cgs = LinearOperator((d,d), matvec=A_cgs_fun, dtype='float')

    def compute_p_inv_A(b, z0):
        (z,info) = sp.sparse.linalg.cgs(A_cgs, vec(b), x0=vec(z0), tol=1e-3, maxiter=100)
        if info > 0:
            print('cgs convergence to tolerance not achieved')
        elif info <0:
            print('cgs gets illegal input or breakdown')
        z = np.reshape(z, x_shape, order='F')
        return z


    def A_cgs_fun_init(x):
        x = np.reshape(x, x_shape, order='F')
        y = AT_fun(A_fun(x))
        return vec(y)
    A_cgs_init = LinearOperator((d,d), matvec=A_cgs_fun_init, dtype='float')

    def compute_init(b, z0):
        (z,info) = sp.sparse.linalg.cgs(A_cgs_init, vec(b), x0=vec(z0), tol=1e-2)
        if info > 0:
            print('cgs convergence to tolerance not achieved')
        elif info <0:
            print('cgs gets illegal input or breakdown')
        z = np.reshape(z, x_shape, order='F')
        return z

    # initialize z and u
    z = compute_init(ATy, ATy)
    u = np.zeros(x_shape)
    v = np.zeros(x_shape)

    plot_normalozer = matplotlib.colors.Normalize(vmin=0.0, vmax=1.0, clip=True)


    start_time = timeit.default_timer()

    for iter in range(max_iter):

        # x-update
        net_input = z-u
        Wzu, wbook = wavelet_transform(net_input)
        q = soft_threshold(Wzu, lambda_l1/alpha)
        x = inverse_wavelet_transform(q, wbook, x_shape)
        x = np.reshape(x, x_shape)

        # z-update
        b = ATy + alpha * (x + u)-AT_fun(v)
        z = compute_p_inv_A(b, z)

        # u-update
        u += x - z;
        v += (A_fun(z)-y)

        if show_img_progress == True:

            fig = plt.figure('current_sol')
            plt.gcf().clear()
            fig.canvas.set_window_title('iter %d' % iter)
            plt.subplot(1,3,1)
            plt.imshow(reshape_img_fun(np.clip(x, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            #plt.imshow(np.clip(x, 0.0, 1.0), interpolation='nearest', norm=plot_normalozer)
            plt.title('x')
            plt.subplot(1,3,2)
            plt.imshow(reshape_img_fun(np.clip(z, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            #plt.imshow(np.clip(z, 0.0, 1.0), interpolation='nearest', norm=plot_normalozer)
            plt.title('z')
            plt.subplot(1,3,3)
            plt.imshow(reshape_img_fun(np.clip(net_input, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            plt.title('netin')
            plt.pause(0.00001)


        obj_ls = 0.5 * np.sum(np.square(y - A_fun(x)))
        x_z = np.sqrt(np.mean(np.square(x-z)))
        u_norm = np.sqrt(np.mean(np.square(u)))

        print('iter = %d: obj_ls = %.3e  |x-z| = %.3e  u_norm = %.3e' % (iter, obj_ls, x_z, u_norm))


        obj_lss[iter] = obj_ls
        x_zs[iter] = x_z
        u_norms[iter] = u_norm
        times[iter] = timeit.default_timer() - start_time


        ## save images
        #filename = '%s/%d-x.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(x, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))
        #filename = '%s/%d-z.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(z, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))
        #filename = '%s/%d-u.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(u, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))

        #_ = raw_input('')

        if x_z < solver_tol:
            break

    infos = {'obj_lss': obj_lss, 'x_zs': x_zs, 'u_norms': u_norms,
             'times': times, 'alpha':alpha, 'lambda_l1':lambda_l1,
             'max_iter':max_iter, 'solver_tol':solver_tol}


    return (x, z, u, infos)

"""Setup for inpaint centre"""

import numpy as np
import scipy as sp
#from vec import vec
import matplotlib.pyplot as plt


def setup_inpaint_centre(x_shape, box_size):


    mask = np.ones(x_shape)


    idx_row = np.round(float(x_shape[0]) / 2.0 - float(box_size) / 2.0).astype(int)
    idx_col = np.round(float(x_shape[1]) / 2.0 - float(box_size) / 2.0).astype(int)

    mask[idx_row:idx_row+box_size,idx_col:idx_col+box_size,:] = 0.


    def A_fun(x):
        y = np.multiply(x, mask);
        return y

    def AT_fun(y):
        x = np.multiply(y, mask);
        return x

    return (A_fun, AT_fun, mask)

"""Setup pixelwise inpaint"""

def setup_pixelwise_inpaint(x_shape, drop_prob = 0.5):

    mask = np.random.rand(*x_shape) > drop_prob;
    mask = mask.astype('double')

    def A_fun(x):
        y = np.multiply(x, mask);
        return y

    def AT_fun(y):
        x = np.multiply(y, mask);
        return x

    return (A_fun, AT_fun, mask)

"""Setup scattered inpaint"""

""" currently only support width (and height) * resize_ratio is an interger! """
def setup_scattered_inpaint(x_shape, box_size, total_box = 10):

    spare = 0.25 * box_size

    mask = np.ones(x_shape)

    for i in range(total_box):

        start_row = spare
        end_row = x_shape[0] - spare - box_size - 1
        start_col = spare
        end_col = x_shape[1] - spare - box_size - 1

        idx_row = int(np.random.rand(1) * (end_row - start_row) + start_row)
        idx_col = int(np.random.rand(1) * (end_col - start_col) + start_col)

        mask[idx_row:idx_row+box_size,idx_col:idx_col+box_size,:] = 0.


    def A_fun(x):
        y = np.multiply(x, mask);
        return y

    def AT_fun(y):
        x = np.multiply(y, mask);
        return x

    return (A_fun, AT_fun, mask)

"""Setup compressive sensing"""

def setup_cs(x_shape, compress_ratio=0.1):

    d = np.prod(x_shape).astype(int)
    m = np.round(compress_ratio * d).astype(int)

    A = tf.random.normal([m,d], dtype=tf.float64)/np.sqrt(m)#np.random.randn(m,d) / np.sqrt(m)
    print("A.shape", A.shape)

    def A_fun(x):
        #print("A.shape", A.shape)
        xd = tf.reshape(x,[d])
        #print("xd.shape", xd.shape)
        y = tf.linalg.matvec(A, xd)#np.dot(A, np.reshape(x,[d], order='F'))#x.ravel(order='F'))
        y = tf.reshape(y, [1,m])#np.reshape(y, [1, m], order='F')
        return y

    def AT_fun(y):
        #print("A.shape", A.shape)
        y = tf.reshape(y, [m])#np.reshape(y, [m, 1], order='F')
        #print("y.shape", y.shape)
        x = tf.linalg.matvec(A, y, transpose_a=True)#np.dot(A.T, y)
        x = tf.reshape(x, x_shape)#np.reshape(x, x_shape, order='F')
        return x

    return (A_fun, AT_fun, A)

"""Setup super resolution"""

def setup_sr2(x_shape):
  filts = tf.constant([0.5,0.5], dtype=tf.float64)
  filts3D = []
  for k in range(x_shape[2]):
        filt2D = tf.pad([tf.tensordot(filts, filts, axes=0)],[[k,x_shape[2]-k-1],[0,0],[0,0]],mode="CONSTANT", constant_values=0)
        filts3D.append(filt2D)
  filters = tf.stack(filts3D)
  filters = tf.transpose(filters,[2,3,0,1])
  #print("filters.shape",filters.shape)
  #print("filters",filters)

  ifilts = tf.constant([1.0,1.0], dtype=tf.float64)
  ifilts3D = []
  #print("x_shape[2]",x_shape[2])
  for k in range(x_shape[2]):
        ifilt2D = tf.pad([tf.tensordot(ifilts, ifilts, axes=0)],[[k,x_shape[2]-k-1],[0,0],[0,0]],mode="CONSTANT", constant_values=0)
        ifilts3D.append(ifilt2D)
  ifilters = tf.stack(ifilts3D)
  ifilters = tf.transpose(ifilters,[2,3,0,1])
  out_shape = [1,x_shape[0],x_shape[1],x_shape[2]]

  def A_fun(x):
    #print("x.shape",x.shape)
    y = tf.nn.conv2d([x],filters,strides=2,padding="VALID")
    return y[0]

  def AT_fun(y):
    x = tf.nn.conv2d_transpose([y],
    ifilters,
    out_shape,
    strides=2,
    padding='VALID',
    data_format='NHWC',
    dilations=None,
    name=None)
    return x[0]

  return (A_fun, AT_fun)

""" currently only support width (and height) * resize_ratio is an interger! """
def setup_sr(x_shape, resize_ratio=0.5):

    box_size = 1.0 / resize_ratio
    if np.mod(x_shape[1], box_size) != 0 or np.mod(x_shape[2], box_size) != 0:
        print("only support width (and height) * resize_ratio is an interger!")


    def A_fun(x):
        y = box_average(x, int(box_size))
        return y

    def AT_fun(y):
        x = box_repeat(y, int(box_size))
        return x

    return (A_fun, AT_fun)



def box_average(x, box_size):
    """ x: [1, row, col, channel] """
    im_row = x.shape[0]
    im_col = x.shape[1]
    channel = x.shape[2]
    out_row = np.floor(float(im_row) / float(box_size)).astype(int)
    out_col = np.floor(float(im_col) / float(box_size)).astype(int)
    y = np.zeros((out_row,out_col,channel))
    total_i = int(im_row / box_size)
    total_j = int(im_col / box_size)

    for c in range(channel):
        for i in range(total_i):
            for j in range(total_j):
                avg = np.average(x[i*int(box_size):(i+1)*int(box_size), j*int(box_size):(j+1)*int(box_size), c], axis=None)
                y[i,j,c] = avg

    return y


def box_repeat(x, box_size):
    """ x: [1, row, col, channel] """
    im_row = x.shape[0]
    im_col = x.shape[1]
    channel = x.shape[2]
    out_row = np.floor(float(im_row) * float(box_size)).astype(int)
    out_col = np.floor(float(im_col) * float(box_size)).astype(int)
    y = np.zeros((out_row,out_col,channel))
    total_i = im_row
    total_j = im_col

    for c in range(channel):
        for i in range(total_i):
            for j in range(total_j):
                y[i*int(box_size):(i+1)*int(box_size), j*int(box_size):(j+1)*int(box_size), c] = x[i,j,c]
    return y

"""add noise function"""

def add_noise(x, noise_mean = 0.0, noise_std = 0.1):
    noise = np.random.randn(*x.shape) * noise_std + noise_mean;
    y = x + noise
    return y, noise

def reshape_img(img):
        return img #[0]

IMAGE_SIZE = 64
def pre_process_image(image):
  print("pre_process image.shape", image.shape)
  image = tf.cast(image, tf.float64)
  image = image / 255.0
  print("pre_process image.shape resized", image.shape, image.dtype)
  #image = tf.image.central_crop(image,0.5)
  image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE)) #resize changes type to float32!
  
  print("pre_process image.shape resized", image.shape, image.dtype)
  image = tf.cast(image, tf.float64)
  print("pre_process image.shape resized", image.shape, image.dtype)
  
  return image

def pre_process_entry(image, label):
  image = pre_process_image(image)  
  return image, label

"""Solve inpaint centre L1"""

def solve_inpaint_center(ori_img, reshape_img_fun, head, invhead, mean,
                        box_size=1, noise_mean=0, noise_std=0.,
                            alpha=0.3, lambda_l1=0.1, max_iter=100, solver_tol=1e-2, problem='inpaint_center', show_img_progress=False):
        #import inpaint_center as problem
        x_shape = ori_img.shape
        print("x_shape", x_shape)
        if (problem=='inpaint_center'):
          (A_fun, AT_fun, mask) = setup_inpaint_centre(x_shape, box_size=box_size)
        elif (problem=='inpaint_scattered'):
          (A_fun, AT_fun, mask) = setup_scattered_inpaint(x_shape, box_size=box_size)
        elif (problem=='inpaint_pixelwise'):
          (A_fun, AT_fun, mask) = setup_pixelwise_inpaint(x_shape)
        elif (problem == 'cs'):
          (A_fun, AT_fun, A) = setup_cs(x_shape)
        elif (problem == 'sr'):
          (A_fun, AT_fun) = setup_sr2(x_shape)
        y, noise = add_noise(A_fun(ori_img), noise_mean=noise_mean, noise_std=noise_std)

        if True:#show_img_progress:
            fig = plt.figure(problem)
            plt.gcf().clear()
            fig.canvas.set_window_title(problem)
            plt.subplot(1,3,1)
            plt.imshow(reshape_img_fun(ori_img), interpolation='nearest')
            plt.title('ori_img')
            plt.subplot(1,3,2)
            plt.imshow(reshape_img_fun(y), interpolation='nearest')
            plt.title('y')
            if (problem!='sr' and problem!='cs'):
              plt.subplot(1,3,3)
              plt.imshow(reshape_img_fun(mask), interpolation='nearest')
              plt.title('mask')
            plt.pause(0.00001)

        info = {'ori_img': ori_img, 'y': y, 'noise': noise,  'box_size': box_size, 'noise_std': noise_std,
                'alpha': alpha, 'max_iter': max_iter, 'solver_tol': solver_tol, 'lambda_l1': lambda_l1}#'mask': mask,

        # save the problem
        #base_folder = '%s/inpaintcenter_bs%d_std%.2f' % (result_folder, box_size, noise_std)
        #if not os.path.exists(base_folder):
        #    os.makedirs(base_folder)
        #filename = '%s/settings.mat' % base_folder
        #sp.io.savemat(filename, info)
        #filename = '%s/y.jpg' % base_folder
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img(np.clip(y, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))
        #filename = '%s/ori_img.jpg' % base_folder
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img(np.clip(ori_img, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))
        run_ours=True
        if run_ours:
            # ours
        #    folder = '%s/ours_alpha%f' % (base_folder, alpha)
        #    if not os.path.exists(folder):
        #        os.makedirs(folder)
            (x, z, u, infos) = solve_pcaw(y, A_fun, AT_fun, lambda_l1,reshape_img_fun, head, invhead, mean, #folder,
                                          show_img_progress=show_img_progress, alpha=alpha,
                                          max_iter=max_iter, solver_tol=solver_tol)
        #    save_results(folder, infos, x, z, u)
        run_l1 = False
        if run_l1:
            # wavelet l1
            #folder = '%s/l1_lambdal1%f_alpha%f' % (base_folder, lambda_l1, alpha_l1)
            #if not os.path.exists(folder):
            #    os.makedirs(folder)
            (x, z, u, infos) = solve_l1_alt(y, A_fun, AT_fun, lambda_l1, reshape_img_fun, #folder,
                                            show_img_progress=show_img_progress, alpha=alpha,
                                            max_iter=max_iter, solver_tol=solver_tol)
            #save_results(folder, infos, x, z, u)

        z1 = reshape_img(np.clip(z, 0.0, 1.0)) #changed from z, bpt
        ori_img1 = reshape_img(np.clip(ori_img, 0.0, 1.0)) 
        psnr_z = 10*np.log10( 1.0 /((np.linalg.norm(z1-ori_img1)**2)/np.prod(z1.shape))) # change * to / ?
        print("psnr_z = ", psnr_z) 
        z1 = reshape_img(np.clip(x, 0.0, 1.0)) #changed from z, bpt
        #ori_img1 = reshape_img(np.clip(ori_img, 0.0, 1.0)) 
        psnr_x = 10*np.log10( 1.0 /((np.linalg.norm(z1-ori_img1)**2)/np.prod(z1.shape))) # change * to / ?
        print("psnr_x = ", psnr_x)  
        #img = Image.fromarray( sp.misc.imresize(np.uint8(z1*255), 4.0, interp='nearest' ) )
        #draw = ImageDraw.Draw(img)
        ##font = ImageFont.truetype(font='tnr.ttf', size=50)
        ##draw.text((135, 200), "%.2f"%psnr, (255,255,255), font=font)
        #filename = '%s/z.jpg' % folder
        #img.save(filename)
        if True:#show_img_progress:
            fig = plt.figure('current_sol')
            plt.gcf().clear()
            fig.canvas.set_window_title('final')
            plt.subplot(1,3,1)
            plt.imshow(reshape_img_fun(np.clip(x, 0.0, 1.0)), interpolation='nearest')
            #plt.imshow(np.clip(x, 0.0, 1.0), interpolation='nearest', norm=plot_normalozer)
            plt.title('x')
            plt.subplot(1,3,2)
            plt.imshow(reshape_img_fun(np.clip(z, 0.0, 1.0)), interpolation='nearest')
            #plt.imshow(np.clip(z, 0.0, 1.0), interpolation='nearest', norm=plot_normalozer)
            plt.title('z')
            plt.subplot(1,3,3)
            plt.imshow(reshape_img_fun(np.clip(u, 0.0, 1.0)), interpolation='nearest')
            plt.title('netin')
            plt.pause(0.00001)

            fig = plt.figure('inpaint_center')
            plt.gcf().clear()
            fig.canvas.set_window_title('inpaint_center')
            plt.subplot(1,3,1)
            plt.imshow(reshape_img_fun(ori_img), interpolation='nearest')
            plt.title('ori_img')
            plt.subplot(1,3,2)
            plt.imshow(reshape_img_fun(y), interpolation='nearest')
            plt.title('y')
            if (problem!='sr' and problem!='cs'):
              plt.subplot(1,3,3)
              plt.imshow(reshape_img_fun(mask), interpolation='nearest')
              plt.title('mask')
            plt.pause(0.00001)
        return psnr_z,psnr_x

class TrainingGenerator:
  def __init__(self):
    self.batch_size = 64
    self.data_dir = '/home/bpt/onenet/du-admm/diff_unrolled_admm_onenet/img_align_celeba'
    self.img_height = 64
    self.img_width = 64
    import os
    cwd = os.getcwd() 
    print("cwd",cwd)
    self.idg = tf.keras.preprocessing.image.ImageDataGenerator()
    #self.iter = tf.keras.preprocessing.image.DirectoryIterator(
    #    self.data_dir, self.idg, target_size=(self.img_width, self.img_height), color_mode='rgb',
    #    classes=None, class_mode='input', batch_size=32, shuffle=True, seed=None,
    #    data_format=None, save_to_dir=None, save_prefix='', save_format='jpg',
    #    follow_links=False, subset=None, interpolation='bilinear', dtype=None)
    self.iter = self.idg.flow_from_directory(self.data_dir, 
            target_size=(self.img_width, self.img_height), 
            color_mode='rgb', classes=['train'], class_mode='input', batch_size=1, 
            shuffle=True, seed=None, save_to_dir=None, save_prefix='', 
            save_format='png', follow_links=False, subset=None, 
            interpolation='bilinear')
    #print("self.iter.filepaths", self.iter.filepaths)
    #print("self.iter.filepaths[0]", self.iter.filepaths[0])
    #print("self.iter.labels", self.iter.labels)

  def __iter__(self):
    return self

  def __next__(self):
    return self.iter.__next__()
    
"""Import some data to play with"""
def import_data():
    import tensorflow_datasets as tfds
    #dataset, metadata = tfds.load('cycle_gan/horse2zebra',
    #                              with_info=True, as_supervised=True)
    #dataset = dataset['trainA']
    #train_horses, train_zebras = dataset['trainA'], dataset['trainB']
    #test_horses, test_zebras = dataset['testA'], dataset['testB']
    #first_1_percent = tfds.Split.VALIDATION.subsplit(tfds.percent[:1])
    dataset, metadata = tfds.load('downsampled_imagenet/64x64:2.0.0', #split='validation[:1%]',#first_1_percent,#tfds.Split.VALIDATION,
                                  with_info=True, as_supervised=False)#, download=False)
    #dataset=dataset['validation']
    #dataset=dataset['train']
    #print("dataset type", type(dataset))
                            
    #training = dataset['TRAIN']
    #validation = dataset['VALIDATION']

    #dataset, metadata = tfds.load('imagenette/160px',#'lfw', #split='validation[:1%]',#first_1_percent,#tfds.Split.VALIDATION,
    #                          with_info=True, as_supervised=False)#, download=False)
    
    #dataset, metadata = tfds.load('downsampled_imagenet/64x64',
    #                            with_info=True, as_supervised=False)
    #dataset = dataset['train']
    #dataset = import_celeba_local()
    return dataset

def import_celeba_local():
    batch_size = 64
    data_dir = 'du-admm/diff_unrolled_admm_onenet/img_align_celeba/train/'
    img_height = 64
    img_width = 64
    # Not in TF 2.0.0
    #train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    #    data_dir,
    #    validation_split=0.2,
    #    subset="training",
    #    seed=123,
    #    image_size=(img_height, img_width),
    #    batch_size=batch_size)
    
    #gen = TrainingGenerator()
    #for i in range(2):
    #    img = gen.__next__()
    #    print("img", img)

    dataset = tf.data.Dataset.from_generator(TrainingGenerator, (tf.float32), (2, 1, 64, 64, 3))
    
    #for value in dataset.take(2):
    #    print(value)
    #    print(value[0])
    #    print(value[1])
    dataset = dataset.map(lambda x:x[0,0,:,:,:])
    return dataset
    
    """Import library for pca-wavelets"""
import pca_wavelet_utils
#!pip install import_ipynb
#from google.colab import drive
#drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %run '/content/drive/My Drive/Colab Notebooks/pca_wavelet_utils.ipynb'

"""Set up activation functions"""

def scaledtanh(x):
  return tf.math.tanh(x*0.1)

def scaledatanh(x):
  return tf.math.atanh(x)*10.0

"""Build the model for pca-wavelet"""
def build_model(dataset):
    from pca_wavelet_utils import build1D
    tf.keras.backend.set_floatx('float64')
    trainset = dataset['train'].map(lambda x:[pre_process_image(x['image'])])
    testset = dataset['validation'].map(lambda x:[pre_process_image(x['image'])])
    #testset = dataset_resize.take(500)
    #trainset = dataset_resize.skip(500)
    #testset = dataset['validation']
    #trainset = dataset['train']
    head, invhead = build1D(trainset,count=4, samplesize=1281149, keep_percent=1.0, flip=False) #, activity_regularizer=scaledtanh, inverse_activity_regularizer=scaledatanh)
    return head, invhead, trainset, testset

"""Save the model"""
def save_model():
    sample = next(iter(testset.shuffle(100)))[0]
    sample = tf.reshape(sample, [1,sample.shape[0], sample.shape[1], sample.shape[2]])
    head._set_inputs(sample)
    head.save('/content/drive/My Drive/Colab Notebooks/data/imagenet/lfw-head-full.h5')
    out = head(sample)
    print("out.shape",out.shape)
    sample = invhead(out)
    #invhead._set_inputs(out)
    invhead.save('/content/drive/My Drive/Colab Notebooks/data/imagenet/lfw-invhead-full.h5')

"""Load the model"""
def load_model():
    head = tf.keras.models.load_model('/content/drive/My Drive/Colab Notebooks/data/imagenet/lfw-head-full.h5', custom_objects={'MeanLayer': MeanLayer, 'SymmetricPadding2D':SymmetricPadding2D})
    invhead = tf.keras.models.load_model('/content/drive/My Drive/Colab Notebooks/data/imagenet/lfw-invhead-full.h5')

"""Save the weights only"""
def save_weights(head, invhead, testset, file_name):
    sample = next(iter(testset.shuffle(100)))[0]
    sample = tf.reshape(sample, [1,sample.shape[0], sample.shape[1], sample.shape[2]])
    out = head(sample)
    #head._set_inputs(sample)
    #head.save('/content/drive/My Drive/Colab Notebooks/data/imagenet/lfw-head.h5')
    #sample = pre_process_image(sample)
    sample = sample*0.0
    lastLayerIndex = 12#8
    lastLayer = invhead.get_layer(index=lastLayerIndex)
    mean = lastLayer(sample)
    #tf.image.encode_png(mean, compression=0)
    tf.io.write_file(file_name + '-mean.json', tf.io.serialize_tensor(mean))
    head.save_weights(file_name + '-head-weights.h5')
    #head.save('/content/drive/My Drive/Colab Notebooks/data/imagenet/lfw-head', save_format='tf')#.h5')
    out = head(sample)
    print("out.shape",out.shape)
    sample = invhead(out)
    #invhead._set_inputs(out)
    #invhead.save('/content/drive/My Drive/Colab Notebooks/data/imagenet/lfw-invhead.h5')
    invhead.save_weights(file_name + '-invhead-weights.h5')

"""Read the weights back in.  Need to reconstruct the architecture.  To do that I run a small set of images through the build method."""
def load_weights(file_name, keep_percent, trainset, testset):
    from pca_wavelet_utils import build1D
    head, invhead = build1D(trainset.take(100),count=4, samplesize=100, keep_percent=keep_percent,flip=False)
    sample = next(iter(testset.shuffle(100)))[0]
    print("sample.shape",sample.shape)
    sample = tf.reshape(sample, [1,sample.shape[0], sample.shape[1], sample.shape[2]])
    print("after reshape: sample.shape",sample.shape)
    
    #head._set_inputs(sample)
    out = head(sample)
    head.load_weights(file_name + '-head-weights.h5')
    out = head(sample)
    print("out.shape",out.shape)
    sample = invhead(out)
    invhead.load_weights(file_name + '-invhead-weights.h5')
    mean = tf.io.parse_tensor(tf.io.read_file(file_name + '-mean.json'),out_type=tf.float64)
    lastLayerIndex = 12#8
    lastLayer = invhead.get_layer(index=lastLayerIndex)
    lastLayer.mean = mean
    firstLayer = head.get_layer(index=0)
    firstLayer.mean = -mean
    return head, invhead, mean

"""Check it has built OK"""
def check_build():
    plt.subplot(221)
    plt.title('Original')
    sample = next(iter(testset.shuffle(100)))[0]#['image']#[0] #train_zebras
    #sample = pre_process_image(sample)

    plt.imshow(sample)#decom[:,:,0])
    print("sample.shape",sample.shape)
    #print("sample",sample)

    #img = tf.cast(sample_horse[0], tf.float64)/255.0
    #img = tf.transpose(img,[0,1,2,3])
    pred = head([sample])
    #argmax = tf.math.argmax(pred)
    #print("argmax",argmax)

    #print("argmax max",pred[argmax])
    #argmin = tf.math.argmin(pred)
    #print("argmin",argmin)
    #print("argmin min",pred[argmin])

    plt.subplot(222)
    plt.title('Slice')
    plt.imshow(pred[0,:,:,0]+0.5)
    plt.subplot(223)
    plt.title('Slice')
    plt.imshow(pred[0,:,:,1]+0.5)
    #img = tf.pad([img],[[0,0],[2,2],[2,2],[0,0]],"SYMMETRIC")
    #print("pred0.shape",pred0.shape)
    #pred0 = tf.pad(pred0,[[0,0],[2,2],[2,2],[0,0]],"SYMMETRIC")
    #pred1 = head.layers[1](pred0)
    print("pred.shape",pred.shape)
    #pred = tf.clip_by_value(pred, -0.9999, 0.9999, name=None)
    #print("invhead.layers[0].bias.shape",invhead.layers[0].bias.shape)
    #print("invhead.layers[1].bias_initializer.value.shape",invhead.layers[1].bias_initializer.value.shape)
    recon = invhead(pred)[0]
    print("recon.shape",recon.shape)
    plt.subplot(224)
    plt.title('Filtered')
    plt.imshow(recon)#decom[:,:,0])
    print("sample.dtype",sample.dtype)
    print("recon[0].dtype",recon.dtype)
    #print("recon[0]",recon)
    print("np.prod(sample.shape)",np.prod(sample.shape))
    psnr = 10*np.log10( 1.0 /((np.linalg.norm(recon-sample)**2)/np.prod(sample.shape))) # changed
    ncc = np.corrcoef(tf.reshape(sample, [-1]), tf.reshape(recon, [-1]))
    print("psnr = ", psnr)
    print("ncc = ", ncc)
    print("sample[30:34,30:34,0]",sample[30:34,30:34,0])
    print("recon[30:34,30:34,0]",recon[30:34,30:34,0])

"""Solver for PCA wavelet"""

# A_fun, AT_fun takes a vector (d,1) or (d,) as input
def solve_pcaw(y, A_fun, AT_fun, lambda_l1, reshape_img_fun, head, invhead, mean, show_img_progress=False, alpha=0.2, max_iter=100, solver_tol=1e-6):
    """ See Wang, Yu, Wotao Yin, and Jinshan Zeng. "Global convergence of ADMM in nonconvex nonsmooth optimization."
    arXiv preprint arXiv:1511.06324 (2015).
    It provides convergence condition: basically with large enough alpha, the program will converge. """

    #result_folder = '%s/iter-imgs' % base_folder
    #if not os.path.exists(result_folder):
        #os.makedirs(result_folder)

    obj_lss = np.zeros(max_iter)
    x_zs = np.zeros(max_iter)
    u_norms = np.zeros(max_iter)
    times = np.zeros(max_iter)

    ATy = AT_fun(y)
    x_shape = ATy.shape
    d = np.prod(x_shape)
    
    def vec(x): #version from vec, don't these two clash
      return tf.reshape(x, [-1])#np.reshape(x, (-1), order='F')

    def A_cgs_fun(x):
        x = tf.reshape(x,x_shape)#np.reshape(x, x_shape, order='F')
        y = AT_fun(A_fun(x)) + alpha * x
        return vec(y)
    A_cgs = LinearOperator((d,d), matvec=A_cgs_fun, dtype='float')

    def compute_p_inv_A(b, z0):
        (z,info) = sp.sparse.linalg.cgs(A_cgs, vec(b), x0=vec(z0), tol=1e-3, maxiter=100)
        if info > 0:
            print('cgs convergence to tolerance not achieved')
        elif info <0:
            print('cgs gets illegal input or breakdown')
        z = tf.reshape(z, x_shape)#np.reshape(z, x_shape, order='F')
        return z


    def A_cgs_fun_init(x):
        x = tf.reshape(x, x_shape)#np.reshape(x, x_shape, order='F')
        y = AT_fun(A_fun(x))
        return vec(y)
    A_cgs_init = LinearOperator((d,d), matvec=A_cgs_fun_init, dtype='float')

    def compute_init(b, z0):
        (z,info) = sp.sparse.linalg.cgs(A_cgs_init, vec(b), x0=vec(z0), tol=1e-2)
        if info > 0:
            print('cgs convergence to tolerance not achieved')
        elif info <0:
            print('cgs gets illegal input or breakdown')
        z = tf.reshape(z,x_shape)#np.reshape(z, x_shape, order='F')
        return z

    # initialize z and u
    z = tf.reshape(mean,x_shape)#.reshape(x_shape)#compute_init(ATy, ATy)
    u = np.zeros(x_shape)
    #print("z.shape",z.shape,flush=True)

    plot_normalozer = matplotlib.colors.Normalize(vmin=0.0, vmax=1.0, clip=True)


    start_time = timeit.default_timer()

    for iter in range(max_iter):

        # x-update
        net_input = z+u
        #print("net_input.shape",net_input.shape)
        #Wzu, wbook = wavelet_transform(net_input)
        Wzu = head([net_input])
        q = tfp.math.soft_threshold(Wzu, lambda_l1/alpha)
        #x = inverse_wavelet_transform(q, wbook, x_shape)
        x = invhead(q)[0] #was q
        #x = np.reshape(x, x_shape)

        # z-update
        b = ATy + alpha * (x - u)
        z = compute_p_inv_A(b, z)

        # u-update
        u += z - x;

        if show_img_progress == True:

            fig = plt.figure('current_sol')
            plt.gcf().clear()
            fig.canvas.set_window_title('iter %d' % iter)
            plt.subplot(1,3,1)
            plt.imshow(reshape_img_fun(np.clip(x, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            #plt.imshow(np.clip(x, 0.0, 1.0), interpolation='nearest', norm=plot_normalozer)
            plt.title('x')
            plt.subplot(1,3,2)
            plt.imshow(reshape_img_fun(np.clip(z, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            #plt.imshow(np.clip(z, 0.0, 1.0), interpolation='nearest', norm=plot_normalozer)
            plt.title('z')
            plt.subplot(1,3,3)
            plt.imshow(reshape_img_fun(np.clip(net_input, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            plt.title('netin')
            plt.pause(0.00001)


        obj_ls = 0.5 * np.sum(np.square(y - A_fun(x)))
        x_z = np.sqrt(np.mean(np.square(x-z)))
        u_norm = np.sqrt(np.mean(np.square(u)))

        #print('iter = %d: obj_ls = %.3e  |x-z| = %.3e  u_norm = %.3e' % (iter, obj_ls, x_z, u_norm))


        obj_lss[iter] = obj_ls
        x_zs[iter] = x_z
        u_norms[iter] = u_norm
        times[iter] = timeit.default_timer() - start_time


        ## save images
        #filename = '%s/%d-x.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(x, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))
        #filename = '%s/%d-z.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(z, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))
        #filename = '%s/%d-u.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(u, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))

        #_ = raw_input('')

        if x_z < solver_tol:
            break

    infos = {'obj_lss': obj_lss, 'x_zs': x_zs, 'u_norms': u_norms,
             'times': times, 'alpha':alpha, 'lambda_l1':lambda_l1,
             'max_iter':max_iter, 'solver_tol':solver_tol}


    return (x, z, u, infos)

"""Alternative version of the ADMM formulas based on my own derivation.
Problem is formulated as follows.  Rather than minimizing:

$\chi^2 =  \lambda f(x) + ||Ax-y||^2$

(which is a regularised version of the original problem), with some unknown weighting variable $\lambda$, instead we minimize $f(x)$ subject to the constraints $Az=y$ and $x=z$.  Using the augmented lagrangian method this leads to minimizing:

$\chi^2 =  f(x) + \frac{\rho}{2}||Az-y||^2+\frac{\rho}{2}||x-z||^2+\lambda_1^T(Az-y)+\lambda_2^T(x-z)$

First solve for $x_{k+1}$:

$x_{k+1} = argmin_x  f(x) + \frac{\rho}{2}||x-z||^2+\lambda_2^T(x-z)$

If we notice that $\frac{\rho}{2}(x-z-u)^2+\frac{\rho}{2}u^2=\frac{\rho}{2}(x-z)^2+\lambda_2^T(x-z)$ if $\lambda_2=-\rho u$, then:

$x_{k+1} = argmin_x  f(x) + \frac{\rho}{2}||x-z-u||^2$

and the solution to this, when $f(x)$ is the $L_1$ norm in the wavelet basis, is the soft thresholding of $f(u+z)$.

Second solve for $z_{k+1}$:

$z_{k+1} = argmin_z \frac{\rho}{2}||Az-y||^2+\frac{\rho}{2}||x-z||^2+\lambda_1^T(Az-y)+\rho u^T(x-z)$

$z_{k+1} = argmin_z \frac{\rho}{2}||Az-y||^2+\frac{\rho}{2}||x-z-u||^2+\lambda_1^T(Az-y)$

$z_{k+1} = argmin_z \frac{\rho}{2}||Az-y-v||^2+\frac{\rho}{2}||x-z-u||^2$, where $\lambda_2 = -\rho v$

This is solved as directly by taking the derivative wrt z and setting to zero.  Clearly the result does not depend on $\rho$ i.e.:

$A^T(Az_{k+1}-y-v)-(x-z_{k+1}-u)=0$

$z_{k+1} = (A^TA+I)^{-1}(A^T(v+y)-x+u)$

Finally the updates to the augmented Lagrangian variables:

$\lambda_1 \leftarrow \lambda_1+\rho(Az-y)$

$\lambda_2 \leftarrow \lambda_2+\rho(x-z)$

In terms of the new variables $u$ and $v$ these become:

$v \leftarrow v-Az+y$

$u \leftarrow u - x+z$

When the projection operator is unable to exactly reconstruct the image, this can result in artefacts in later iterations.  It is like the algorithm is becoming increasingly desperate to make corrections that it is unable to achieve, corrupting other parts of the reconstruction.  We have considered 2 ways to try and prevent this.  Both involve making $x$ an inexact version of $z$, either by incorporating a small reconstruction error that we try to minimize, or by explicitly making $x$ equal to a projection of $z$ into the model space.  In the first we try to minimize:

$\chi^2 =  f(x) + \lambda ||x-z||^2$

subject to the constraint $Az=y$.  This is solved using:

$x_{k+1} = argmin_x f(x)+\lambda||x-z||^2$ (soft threshold of z)

$z_{k+1} = (\rho A^TA + 2\lambda I)^{-1}(2\lambda x + \rho A^T(y+v)$

$v_{k+1} = v-Az+y$

In the second we try to minimize $f(x)$ subject to the constraints $Az=y$ and $x=P(z)$ where $P$ is the projection operator (perform our decomposition and reconstruction).  The solution to this involves a lot of $P^T$ (if $P$ is linear) which is unclear what it is (probably similar to $P$) and a more complex matrix inversion to solve.  Left for future work.
"""

import  tensorflow_probability as tfp
# A_fun, AT_fun takes a vector (d,1) or (d,) as input
def solve_pcaw_alt(y, A_fun, AT_fun, lambda_l1, reshape_img_fun, show_img_progress=False, alpha=0.2, max_iter=100, solver_tol=1e-6):
    """ See Wang, Yu, Wotao Yin, and Jinshan Zeng. "Global convergence of ADMM in nonconvex nonsmooth optimization."
    arXiv preprint arXiv:1511.06324 (2015).
    It provides convergence condition: basically with large enough alpha, the program will converge. """

    #result_folder = '%s/iter-imgs' % base_folder
    #if not os.path.exists(result_folder):
        #os.makedirs(result_folder)

    obj_lss = np.zeros(max_iter)
    x_zs = np.zeros(max_iter)
    u_norms = np.zeros(max_iter)
    times = np.zeros(max_iter)

    ATy = AT_fun(y)
    x_shape = ATy.shape
    d = np.prod(x_shape)
    
    def vec(x): #version from vec, don't these two clash
      return np.reshape(x, (-1), order='F')

    def Proj(x):
      #y = invhead(head([x]))
      #return y[0]
      return x
    def A_cgs_fun(x):
        x = np.reshape(x, x_shape, order='F')
        y = AT_fun(A_fun(x)) + x #Proj(Proj(x))#x#alpha 
        return vec(y)

    A_cgs = LinearOperator((d,d), matvec=A_cgs_fun, dtype='float')

    def compute_p_inv_A(b, z0):
        (z,info) = sp.sparse.linalg.cgs(A_cgs, vec(b), x0=vec(z0), tol=1e-3, maxiter=100)
        if info > 0:
            print('cgs convergence to tolerance not achieved')
        elif info <0:
            print('cgs gets illegal input or breakdown')
        z = np.reshape(z, x_shape, order='F')
        return z


    def A_cgs_fun_init(x):
        x = np.reshape(x, x_shape, order='F')
        y = AT_fun(A_fun(x))
        return vec(y)
    A_cgs_init = LinearOperator((d,d), matvec=A_cgs_fun_init, dtype='float')

    def compute_init(b, z0):
        (z,info) = sp.sparse.linalg.cgs(A_cgs_init, vec(b), x0=vec(z0), tol=1e-2)
        if info > 0:
            print('cgs convergence to tolerance not achieved')
        elif info <0:
            print('cgs gets illegal input or breakdown')
        z = np.reshape(z, x_shape, order='F')
        return z

    # initialize z and u
    z = mean#compute_init(ATy, ATy)
    u = np.zeros(x_shape)
    v = np.zeros(x_shape)

    plot_normalozer = matplotlib.colors.Normalize(vmin=0.0, vmax=1.0, clip=True)


    start_time = timeit.default_timer()

    for iter in range(max_iter):

        # x-update
        print("z.shape",z.shape)
        #if (iter<30):
        net_input = z-u#z+u
        #else:
        #  net_input = Proj(z)-u#z+u
        #net_input = z  
        print("net_input.shape",net_input.shape)
        #Wzu, wbook = wavelet_transform(net_input)
        q = head([net_input])
        #q = tf.clip_by_value(q,-0.9999,0.9999)
        q = tfp.math.soft_threshold(q, lambda_l1/alpha)
        #x = inverse_wavelet_transform(q, wbook, x_shape)
        x = invhead(q)[0] #was q
        #x = np.reshape(x, x_shape)

        # z-update

        b = ATy  + (alpha*(x + u)) - AT_fun(v)
        #b = lambda_l1*(ATy- AT_fun(v))  + alpha*x 
        z = compute_p_inv_A(b, z)

        # u-update
        u += Proj(x - (z))
        v += (A_fun(z)-y)
        #lambda_l1 = lambda_l1*2

        obj_ls = 0.5 * np.sum(np.square(y - A_fun(x)))
        x_z = np.sqrt(np.mean(np.square(x-z)))
        u_norm = np.sqrt(np.mean(np.square(u)))
        #u_norm = np.sqrt(np.mean(np.square(v)))

        if show_img_progress == True:

            fig = plt.figure('current_sol')
            plt.gcf().clear()
            fig.canvas.set_window_title('iter %d' % iter)
            plt.subplot(1,3,1)
            plt.imshow(reshape_img_fun(np.clip(x, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            #plt.imshow(np.clip(x, 0.0, 1.0), interpolation='nearest', norm=plot_normalozer)
            plt.title('x')
            plt.subplot(1,3,2)
            plt.imshow(reshape_img_fun(np.clip(z, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            #plt.imshow(np.clip(z, 0.0, 1.0), interpolation='nearest', norm=plot_normalozer)
            plt.title('z')
            plt.subplot(1,3,3)
            plt.imshow(reshape_img_fun(np.clip(net_input, 0.0, 1.0)), interpolation='nearest', norm=plot_normalozer)
            plt.title('netin')
            plt.pause(0.00001)
            print('iter = %d: obj_ls = %.3e  |x-z| = %.3e  u_norm = %.3e' % (iter, obj_ls, x_z, u_norm))


        obj_lss[iter] = obj_ls
        x_zs[iter] = x_z
        u_norms[iter] = u_norm
        times[iter] = timeit.default_timer() - start_time


        ## save images
        #filename = '%s/%d-x.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(x, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))
        #filename = '%s/%d-z.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(z, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))
        #filename = '%s/%d-u.jpg' % (result_folder, iter)
        #sp.misc.imsave(filename, sp.misc.imresize((reshape_img_fun(np.clip(u, 0.0, 1.0))*255).astype(np.uint8), 4.0, interp='nearest'))

        #_ = raw_input('')

        if x_z < solver_tol:
            break

    infos = {'obj_lss': obj_lss, 'x_zs': x_zs, 'u_norms': u_norms,
             'times': times, 'alpha':alpha, 'lambda_l1':lambda_l1,
             'max_iter':max_iter, 'solver_tol':solver_tol}


    return (x, z, u, infos)

def extract_mean(invhead, testset):
    #invhead.summary()
    lastLayerIndex = 12#8#invhead.layers.count()
    #plt.subplot(121)
    #plt.title('Original')
    sample = next(iter(testset.take(1)))[0]#'image']
    print("sample.shape",sample.shape)

    #sample = pre_process_image(sample)
    sample = sample*0.0
    lastLayer = invhead.get_layer(index=lastLayerIndex)
    mean = lastLayer([sample])[0]
    print("mean.shape",mean.shape)
    #plt.imshow(mean)#decom[:,:,0])
    #print("mean",mean[0,0,0],mean[0,0,1],mean[0,0,2])

    #net_input = mean
    #q = head([net_input])#[0]*1000+0.5 # .get_layer(index=0)
    #q = tfp.math.soft_threshold(q, 0.02)
    #x = invhead(q)[0]
    #plt.subplot(122)
    #plt.title('Projected')
    #plt.imshow(x)
    return mean

"""Run the solver"""
def run_solver_single():
    problem='inpaint_center'#'sr'
    print('problem', problem)
    #ori_img = train_horses.take(1)[0]
    ori_img = next(iter(testset.shuffle(1000)))[0]#['image']#[0]#train_horses
    #ori_img = pre_process_image(ori_img)
    #ori_img = invhead(head([ori_img]))[0] #test
    show_img_progress = True#False#
    # No noise alpha = 0.1, lambda=0.0005 seems to work well (in painting problems, at least)
    # Noise = 0.1, alpha = 0.3, lambda = 0.0015, or alpha = 0.6, lambda = 0.003 seem to work about the same
    # Super resolution, no noise settings seems OK
    # Compressive Sensing, 0.1 and 0.005 worked quite well, maybe more iterations needed?
    alpha = 0.1#0.01#0.3#0.2#1.0#
    max_iter = 100
    solver_tol = 1e-5
    alpha_update_ratio = 1.0
       
    alpha_l1 = 0.3#0.3
    lambda_l1 = 0.0000001#0.02#
    max_iter_l1 = 1000
    solver_tol_l1 = 1e-4
       
    box_size = int(0.3 * ori_img.shape[1])#blockwise - 0.3*shape[1], scattere - 0.1*shape[1]
    noise_std = 0.0

    results = solve_inpaint_center(ori_img, reshape_img, box_size=box_size, noise_std=noise_std, alpha=alpha, lambda_l1=lambda_l1, max_iter=max_iter, solver_tol=solver_tol, problem=problem)#'inpaint_center')#

"""Run the solver on all images in testset and calculate results"""
def run_solver_all(head, invhead, mean, testset, problem):
    
    print("problem", problem)
    it = iter(testset.take(100))#shuffle(500).take(500))#.skip(34))#.take(50))##
    show_img_progress = False#True#
    alpha = 0.3#0.01#0.3#0.2#1.0#
    max_iter = 100
    solver_tol = 1e-5
    alpha_update_ratio = 1.0
       
    alpha_l1 = 0.1#0.3
    lambda_l1 = 0.006#0.02#
    max_iter_l1 = 1000
    solver_tol_l1 = 1e-4
       
    noise_std = 0.0
    mean_x = 0.0
    mean_z = 0.0
    sd_x = 0.0
    sd_z = 0.0
    count = 0.0
    print("alpha", alpha, "lambda_l1", lambda_l1)

    for x in it:
      ori_img = x[0]#['image']#train_horses
      print("ori_img.shape", ori_img.shape, flush=True)
      box_size = int(0.1 * ori_img.shape[1])
      
      psnr_x,psnr_z = solve_inpaint_center(ori_img, reshape_img, head, invhead, mean, box_size=box_size, noise_std=noise_std, alpha=alpha, lambda_l1=lambda_l1, max_iter=max_iter, solver_tol=solver_tol, problem=problem, show_img_progress=False)#inpaint_scattered')#center')#
      mean_x += psnr_x
      sd_x += psnr_x*psnr_x
      mean_z += psnr_z
      sd_z += psnr_z*psnr_z
      count += 1
      print("count",count, "mean_x", mean_x, "sd_x", sd_x, "mean_z",mean_z,"sd_z",sd_z)

    mean_x /= count
    mean_z /= count
    sd_x -= count*mean_x*mean_x
    sd_z -= count*mean_z*mean_z
    sd_x /= (count-1.0)
    sd_z /= (count-1.0)

    print("mean_x",mean_x,"sd_x",sd_x)
    print("mean_z",mean_z,"sd_z",sd_z)

"""Test tensordot as used in the pca calculation."""
def test_tensordot():
    ten = tf.random.normal([3,3,4])
    print("ten",ten)
    mat = tf.reshape(ten,[-1,ten.shape[2]])
    print("mat",mat)
    cov = tf.tensordot(mat,mat,[0,0])
    cov = cov/mat.shape[0]
    print("cov",cov)
    #mult = tf.linalg.matmul(mat,mat, transpose_a=True, transpose_b=False)
    #print("mult",mult)
    #out = tf.zeros([4,4])
    #for i in range(9):
    #  out += tf.linalg.matmul([mat[i,:]],[mat[i,:]], transpose_a=True, transpose_b=False)

    #print("out",out)
    #out2 = tf.tensordot(mat, mat, 0)
    #out2 = tf.matmul(mat[:,:,None],mat[:,None,:])
    #print("out2",out2)
    #out3 = tf.reduce_sum(out2,[0])
    #print("out3",out3)
    sum = tf.reduce_sum(mat,[0])
    sum = sum/mat.shape[0]
    print("sum",sum)
    #m = tf.ones(mat.shape[0], dtype=tf.float32)
    #m = tf.linalg.matvec(mat,m, transpose_a=True)
    #m = m/mat.shape[0]
    #print("m",m)
    mouter = tf.tensordot(sum, sum, axes=0)
    print("mouter",mouter)
    pca = cov-mouter
    print("pca",pca)
    
def main():
    print("python main function")
    print("importing data")
    dataset = import_data()
    #print("building model")
    #head, invhead, trainset, testset = build_model(dataset)
    #print("saving weights")
    #mean = extract_mean(invhead, testset)
    #save_weights(head, invhead, testset, 'imagenet') #celeba-190')#'imagenet-100k')#head, invhead, testset, file_name)
    #tf.keras.backend.set_floatx('float64')
    #dataset_resize = dataset.map(lambda x:[pre_process_image(x['image'])])
    
    #testset = dataset_resize.take(500)
    #trainset = dataset_resize.skip(500)
    tf.keras.backend.set_floatx('float64')
    trainset = dataset['train'].map(lambda x:[pre_process_image(x['image'])])
    testset = dataset['validation'].map(lambda x:[pre_process_image(x['image'])])
    print("loading model")
    head, invhead, mean = load_weights('imagenet', 1.0, trainset, testset)
    print("running solver")
    run_solver_all(head, invhead, mean, testset, 'cs')#inpaint_pixelwise')#inpaint_center')
    
if __name__ == '__main__':
    main()
